import json
import requests

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL = "qwen2.5:7b-instruct"


FORMATTER_SYSTEM_PROMPT = """
You are a response formatter for a data assistant.

You DO NOT:
- generate queries
- modify data
- mention databases, KQL, ADX, MCP, or internal systems

You ONLY:
- explain results clearly
- answer the user's question using the provided data
- handle errors politely

Rules:
- If data is present, summarize it in simple language
- If rows are few, you may list them
- If rows are many, summarize trends
- If an error is present, explain it in simple terms
- Never expose internal fields like trace_id or generated_kql unless explicitly asked
- Be concise, clear, and user-friendly
"""


def format_response(user_query: str, system_json: dict) -> str:
    """
    user_query  : Original user question (string)
    system_json : JSON response returned by backend (/chat internal result)

    Returns a clean, human-readable answer generated by LLM
    """

    prompt = f"""
{FORMATTER_SYSTEM_PROMPT}

User Question:
{user_query}

System Result (JSON):
{json.dumps(system_json, indent=2)}

Generate the best possible answer for the user.
"""

    response = requests.post(
        OLLAMA_URL,
        json={
            "model": MODEL,
            "prompt": prompt,
            "stream": False
        },
        timeout=30
    )

    return response.json()["response"].strip()
